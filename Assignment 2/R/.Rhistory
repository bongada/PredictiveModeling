ridge.test.r2 = 1 - mean((College.test[, "Apps"] - ridge.pred)^2) /mean((College.test[, "Apps"] - test.avg)^2)
lasso.test.r2 = 1 - mean((College.test[, "Apps"] - lasso.pred)^2) /mean((College.test[, "Apps"] - test.avg)^2)
pcr.test.r2 = 1 - mean((College.test[, "Apps"] - data.frame(pcr.pred))^2) /mean((College.test[, "Apps"] - test.avg)^2)
lasso.test.r2 = 1 - mean((College.test[, "Apps"] - lass.pred)^2) /mean((College.test[, "Apps"] - test.avg)^2)
pls.test.r2 = 1 - mean((College.test[, "Apps"] - data.frame(pls.pred))^2) /mean((College.test[, "Apps"] - test.avg)^2)
barplot(c(lm.test.r2, ridge.test.r2, lasso.test.r2, pcr.test.r2, pls.test.r2), col="red", names.arg=c("OLS", "Ridge", "Lasso", "PCR", "PLS"), main="Test R-squared")
lm.test.r2
ridge.test.r2
lasso.test.r2
pcr.test.r2
pls.test.r2
library(MASS)
library(leaps)
library(glmnet)
x = model.matrix(crim ~. -1, data=Boston)
y = Boston$crim
cv.lasso = cv.glmnet(x,y,type.measure = "mse")
plot(cv.lasso)
coef(cv.lasso)
sqrt(cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.1se])
x = model.matrix(crim~.-1, data=Boston)
y = Boston$crim
cv.ride = cv.glmnet(x,y,type.measure = 'mse', alpha=0)
plot(cv.ridge)
cv.ridge = cv.glmnet(x,y,type.measure = 'mse', alpha=0)
plot(cv.ridge)
coef(cv.ridge)
sqrt(cv.ridge$cvm[cv.ridge$lambda == cv.ridge$lambda.1se])
library(pls)
pcr.fit = pcr(crim~.,data=Boston,scale=TRUE,validation="CV")
summary(pcr.fit)
head(Boston)
train = sample(dim(Carseats)[1],dim(Carseats)[1]/2)
Carseats.train = Carseats[train,]
Carseats.test = Carseats[-train,]
library(tree)
install.packages("tree")
library(tree)
tree.carseats = tree(Sales~.,data=Carseats.train)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
pred.carseats = predict(tree.carseats,Carseats.test)
mean((Carseats.test$Sales - pred.carseats)^2)
cv.carseats = cv.tree(tree.carseats, FUN = prune.tree)
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
pruned.carseats = prune.tree(tree.carseats,best=9)
par(mfrow=c(1,1))
plot(pruned.carseats)
text(pruned.carseats, pretty=0)
pred.pruned = predict(pruned.carseats,Carseats.test)
mean((Carseats.test$Sales - pred.pruned)^2)
cv.carseats = cv.tree(tree.carseats, FUN = prune.tree)
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
pruned.carseats = prune.tree(tree.carseats,best=8)
par(mfrow=c(1,1))
plot(pruned.carseats)
text(pruned.carseats, pretty=0)
pred.pruned = predict(pruned.carseats,Carseats.test)
mean((Carseats.test$Sales - pred.pruned)^2)
library(randomForest)
bag.carseats = randomFroest(Sales~.,data=Carseats.train,mtry=10,ntree=500,importance=T)
bag.carseats = randomForest(Sales~.,data=Carseats.train,mtry=10,ntree=500,importance=T)
bag.predict = predict(bag.carseats,Carseats.test)
mean((Carseats.test$Sales-bag.pred)^2)
mean((Carseats.test$Sales-bag.predict)^2)
importance(bag.carseats)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=5,ntree=500,importance=T)
rf.predict = predict(rf.carseats,Carseats.test)
mean((Carseats.test$Sales - rf.predict)^2)
importance(rf.carseats)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=10,ntree=500,importance=T)
rf.predict = predict(rf.carseats,Carseats.test)
mean((Carseats.test$Sales - rf.predict)^2)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=20,ntree=500,importance=T)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=13,ntree=500,importance=T)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=11,ntree=500,importance=T)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=10,ntree=500,importance=T)
rf.predict = predict(rf.carseats,Carseats.test)
mean((Carseats.test$Sales - rf.predict)^2)
rf.carseats = randomForest(Sales~.,data=Carseats.train,mtry=1,ntree=500,importance=T)
rf.predict = predict(rf.carseats,Carseats.test)
mean((Carseats.test$Sales - rf.predict)^2)
library(ISLR)
train = 1:1000
attach(Caravan)
Caravan$Purhcase = ifelse(Caravan$Purchase == "Yes",1,0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
library(gbm)
distribution = "bernoulli")
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,
distribution = "bernoulli")
summary(boost.caravan)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
library(gbm)
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,
distribution = "bernoulli")
summary(boost.caravan)
library(ISLR)
train = 1:1000
attach(Caravan)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
#B
library(gbm)
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,
distribution = "bernoulli")
summary(boost.caravan)
library(ISLR)
train = 1:1000
attach(Caravan)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
library(gbm)
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,
distribution = "bernoulli")
summary(boost.caravan)
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,distribution = "bernoulli")
summary(boost.caravan)
summary(boost.caravan)
train = 1:1000
attach(Caravan)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,distribution = "bernoulli")
summary(boost.caravan)
summary(0,16,boost.caravan)
summary(boost.caravan)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,distribution = "bernoulli")
summary(boost.caravan)
boostcaravansumm = summary(boost.caravan)
boost.prob = predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")
boost.predict = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase,boost.pred)
table(Caravan.test$Purchase,boost.predict)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,distribution = "bernoulli")
boostcaravansumm = summary(boost.caravan)
boost.prob = predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")
boost.predict = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase,boost.predict)
table(Caravan.test$Purchase, boost.predict)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train,]
Caravan.test = Caravan[-train,]
boost.caravan = gbm(Purchase~.,data=Caravan.train,n.trees=1000,shrinkage=0.01,distribution = "bernoulli")
boostcaravansumm = summary(boost.caravan)
boost.prob = predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")
boost.predict = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.predict)
set.seed(342)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01,
distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")
boost.predict = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.predict)
library(ISLR)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
library(gbm)
set.seed(342)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01,
distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
lm.caravan = glm(Purchase ~ ., data = Caravan.train, family = binomial)
lm.prob = predict(lm.caravan,Carava.test,type="response")
lm.prob = predict(lm.caravan,Caravan.test,type="response")
lm.pred = ifelse(lm.prob>0.2,1,0)
table(Caravan.test$Purchase,lm.pred)
head(Caravan)
Caravan$Purhcase <- NULL
head(Caravan)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
head(Caravan)
set.seed(342)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01,
distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
library(ISLR)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
head(Caravan)
library(gbm)
set.seed(342)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01,
distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
lm.caravan = glm(Purchase ~ ., data = Caravan.train, family = binomial)
lm.prob = predict(lm.caravan,Caravan.test,type="response")
lm.pred = ifelse(lm.prob>0.2,1,0)
table(Caravan.test$Purchase,lm.pred)
Caravan$Purhcase <- NULL
head(Caravan)
setwd("~/Documents/UT/Summer 2015/Predictive Modeling")
beauty = read.csv('../BeautyData.csv',header=TRUE)
beauty = read.csv('..BeautyData.csv',header=TRUE)
beauty = read.csv('BeautyData.csv',header=TRUE)
head(beauty)
attach(beauty)
lm.beauty = lm(CourseEvals~BeautyScore)
summary(lm.beauty)
plot(BeautyScore,CourseEvals)
pairs(beauty)
lm.multi = lm(CourseEvals~.,data=beauty)
summary(lm.multi)
lm.multi = lm(CourseEvals~.,data=beauty[,c(2,5,6)])
summary(lm.multi)
lm.multi = lm(CourseEvals~.,data=beauty)
summary(lm.multi)
lm.pbeauty = lm(CourseEvals~.poly(beauty,3))
lm.pbeauty = lm(CourseEvals~poly(beauty,3))
lm.three = lm(CourseEvals ~., data = beauty[,c(2:4)])
summary(lm.three)
importance(beauty)
importance(lm.multi)
cor(BeautyScore,CourseEvals)
cor(BeautyScore,CourseEvals, method = 'Spearman')
cor(BeautyScore,CourseEvals, method = 'spearman')
cor(female,CourseEvals)
cor(lower,CourseEvals)
houses = read.xls('MidCity.xls',header=TRUE)
houses = read.table('MidCity.xls',header=TRUE)
houses = read.csv('MidCity.csv',header=TRUE)
head(houses)
lm.brick = lm(Price~.,data = houses)
summary(lm.brick)
rm(list=ls())
MidCity = read.csv("MidCity.csv",header=T)
attach(MidCity)
n = dim(MidCity)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
BR = rep(0,n)
BR[Brick=="Yes"]=1
Price = Price/1000
SqFt = SqFt/1000
MidCityModel = lm(Price~dn1+dn2+SqFt)
plot(SqFt,Price,xlab="Size")
points(SqFt[dn3==1],Price[dn3==1],col=2,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[2],MidCityModel$coef[4]),col=4,lwd=2)
points(SqFt[dn1==1],Price[dn1==1],col=4,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[3],MidCityModel$coef[4]),col=3,lwd=2)
points(SqFt[dn2==1],Price[dn2==1],col=3,pch=19)
abline(coef=MidCityModel$coef[c(1,4)],col=2,lwd=2)
legend(1.45,210,c("Nbhd = 1","Nbhd = 2","Nbhd = 3","Just Size"),lty=c(1,1,1,2),lwd=c(2,2,2,2),col=c(4,3,2,1))
abline(lsfit(SqFt,Price),col=1,lwd=2,lty=2)
Nbhd = factor(Nbhd)
Nbhd
dn1
n = dim(MidCity)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
MidCityModel = lm(Price~dn1+dn2+SqFt)
plot(SqFt,Price,xlab="Size")
abline(coef=MidCityModel$coef[c(1,4)],col=2,lwd=2)
points(SqFt[dn3==1],Price[dn3==1],col=2,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[2],MidCityModel$coef[4]),col=4,lwd=2)
points(SqFt[dn1==1],Price[dn1==1],col=4,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[3],MidCityModel$coef[4]),col=3,lwd=2)
points(SqFt[dn2==1],Price[dn2==1],col=3,pch=19)
legend(1.45,210,c("Nbhd = 1","Nbhd = 2","Nbhd = 3","Just Size"),lty=c(1,1,1,2),lwd=c(2,2,2,2),col=c(4,3,2,1))
abline(lsfit(SqFt,Price),col=1,lwd=2,lty=2)
Nbhd = factor(Nbhd)
model2 = lm(Price~Nbhd + SqFt + Nbhd:Brick)
summary(model2)
summary(MidCityModel)
summary(lm.brick)
lm.brick = lm(Price~.,data = houses)
houses = read.csv('MidCity.csv',header=TRUE)
head(houses)
lm.brick = lm(Price~.,data = houses)
summary(lm.brick)
attach(houses)
head(houses)
lm.brick = lm(Price~.,data = houses)
summary(lm.brick)
n = dim(MidCity)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
MidCityModel = lm(Price~dn1+dn2+SqFt)
summary(MidCityModel)
plot(SqFt,Price,xlab="Size")
abline(coef=MidCityModel$coef[c(1,4)],col=2,lwd=2)
points(SqFt[dn3==1],Price[dn3==1],col=2,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[2],MidCityModel$coef[4]),col=4,lwd=2)
points(SqFt[dn1==1],Price[dn1==1],col=4,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[3],MidCityModel$coef[4]),col=3,lwd=2)
points(SqFt[dn2==1],Price[dn2==1],col=3,pch=19)
legend(1.45,210,c("Nbhd = 1","Nbhd = 2","Nbhd = 3","Just Size"),lty=c(1,1,1,2),lwd=c(2,2,2,2),col=c(4,3,2,1))
abline(lsfit(SqFt,Price),col=1,lwd=2,lty=2)
Nbhd = factor(Nbhd)
model2 = lm(Price~Nbhd + SqFt + Nbhd:Brick)
summary(model2)
n = dim(houses)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
MidCityModel = lm(Price~dn1+dn2+SqFt)
summary(MidCityModel)
plot(SqFt,Price,xlab="Size")
abline(coef=MidCityModel$coef[c(1,4)],col=2,lwd=2)
points(SqFt[dn3==1],Price[dn3==1],col=2,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[2],MidCityModel$coef[4]),col=4,lwd=2)
points(SqFt[dn1==1],Price[dn1==1],col=4,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[3],MidCityModel$coef[4]),col=3,lwd=2)
points(SqFt[dn2==1],Price[dn2==1],col=3,pch=19)
legend(1.45,210,c("Nbhd = 1","Nbhd = 2","Nbhd = 3","Just Size"),lty=c(1,1,1,2),lwd=c(2,2,2,2),col=c(4,3,2,1))
abline(lsfit(SqFt,Price),col=1,lwd=2,lty=2)
Nbhd = factor(Nbhd)
model2 = lm(Price~Nbhd + SqFt + Nbhd:Brick)
summary(model2)
summary(lm.brick)
rm(list=ls())
MidCity = read.csv("MidCity.csv",header=T)
attach(MidCity)
n = dim(MidCity)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
BR = rep(0,n)
BR[Brick=="Yes"]=1
Price = Price/1000
SqFt = SqFt/1000
MidCityModel = lm(Price~dn1+dn2+SqFt)
houses = read.csv('MidCity.csv',header=TRUE)
attach(houses)
head(houses)
lm.brick = lm(Price~.,data = houses)
summary(lm.brick)
n = dim(houses)[1]
dn1 = rep(0,n)
dn1[Nbhd==1]=1
dn2 = rep(0,n)
dn2[Nbhd==2]=1
dn3 = rep(0,n)
dn3[Nbhd==3]=1
MidCityModel = lm(Price~dn1+dn2+SqFt)
summary(MidCityModel)
plot(SqFt,Price,xlab="Size")
abline(coef=MidCityModel$coef[c(1,4)],col=2,lwd=2)
points(SqFt[dn3==1],Price[dn3==1],col=2,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[2],MidCityModel$coef[4]),col=4,lwd=2)
points(SqFt[dn1==1],Price[dn1==1],col=4,pch=19)
abline(coef=c(MidCityModel$coef[1]+MidCityModel$coef[3],MidCityModel$coef[4]),col=3,lwd=2)
points(SqFt[dn2==1],Price[dn2==1],col=3,pch=19)
legend(1.45,210,c("Nbhd = 1","Nbhd = 2","Nbhd = 3","Just Size"),lty=c(1,1,1,2),lwd=c(2,2,2,2),col=c(4,3,2,1))
abline(lsfit(SqFt,Price),col=1,lwd=2,lty=2)
Nbhd = factor(Nbhd)
model2 = lm(Price~Nbhd + SqFt + Nbhd:Brick)
summary(model2)
georgiavotes = read.csv('../HW1/georgia2000.csv', header = TRUE)
setwd("~/Documents/UT/Summer 2015/Predictive Modeling")
georgiavotes = read.csv('../HW1/georgia2000.csv', header = TRUE)
georgiavotes = read.csv('../HW1/Data/georgia2000.csv', header = TRUE)
georgiavotes = read.csv('../Data/georgia2000.csv', header = TRUE)
georgiavotes = read.csv('../HW1/georgia2000.csv', header = TRUE)
library(tm)
library(e1071)
#library(rpart)
library(ggplot2)
#library(caret)
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
file_list = NULL
training_labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=23)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
training_labels = append(training_labels, rep(author_name, length(files_to_add)))
}
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
training_corpus = Corpus(VectorSource(all_docs))
names(training_corpus) = file_list
training_corpus = tm_map(training_corpus, content_transformer(tolower))
training_corpus = tm_map(training_corpus, content_transformer(removeNumbers))
training_corpus = tm_map(training_corpus, content_transformer(removePunctuation))
training_corpus = tm_map(training_corpus, content_transformer(stripWhitespace))
training_corpus = tm_map(training_corpus, content_transformer(removeWords), stopwords("SMART"))
setwd("~/Documents/UT/Summer 2015/Predictive Modeling/HW2/R")
library(tm)
library(e1071)
#library(rpart)
library(ggplot2)
#library(caret)
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
file_list = NULL
training_labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=23)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
training_labels = append(training_labels, rep(author_name, length(files_to_add)))
}
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
training_corpus = Corpus(VectorSource(all_docs))
names(training_corpus) = file_list
training_corpus = tm_map(training_corpus, content_transformer(tolower))
training_corpus = tm_map(training_corpus, content_transformer(removeNumbers))
training_corpus = tm_map(training_corpus, content_transformer(removePunctuation))
training_corpus = tm_map(training_corpus, content_transformer(stripWhitespace))
training_corpus = tm_map(training_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM_training = DocumentTermMatrix(training_corpus)
DTM_training = removeSparseTerms(DTM_training, 0.975)
DTM_training_df = as.data.frame(inspect(DTM_training))
author_dirs = Sys.glob('../data/ReutersC50/C50test/*')
file_list = NULL
testing_labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=22)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
testing_labels = append(testing_labels, rep(author_name, length(files_to_add)))
}
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
testing_corpus = Corpus(VectorSource(all_docs))
names(testing_corpus) = file_list
testing_corpus = tm_map(testing_corpus, content_transformer(tolower))
testing_corpus = tm_map(testing_corpus, content_transformer(removeNumbers))
testing_corpus = tm_map(testing_corpus, content_transformer(removePunctuation))
testing_corpus = tm_map(testing_corpus, content_transformer(stripWhitespace))
testing_corpus = tm_map(testing_corpus, content_transformer(removeWords), stopwords("SMART"))
training_dict = NULL
training_dict = dimnames(DTM_training)[[2]]
DTM_testing = DocumentTermMatrix(testing_corpus, list(dictionary=training_dict))
DTM_testing = removeSparseTerms(DTM_testing, 0.975)
DTM_testing_df = as.data.frame(inspect(DTM_testing))
NBModel = naiveBayes(x=DTM_training_df, y=as.factor(training_labels), laplace=0)
NBPred = predict(NBModel, DTM_testing_df)
NBTable = as.data.frame(table(NBPred,testing_labels))
NBTable[1:10,]
plot = ggplot(NBTable) + geom_bin2d(aes(x=testing_labels, y=NBPred, fill=Freq)) +
scale_x_discrete(name="Actual Author") +
scale_y_discrete(name="Predicted Author") +
theme(axis.text.x = element_text(angle = 90))
plot
RMSE = sqrt(mean(testing_labels - NBPred)^2)
RMSEdf = NBTable[,]
RMSEdf$rightOrNah <- NBPred == testing_labels
head(RMSEdf)
countdf = count(RMSEdf,c("testing_labels"))
library(plyr)
countdf = count(RMSEdf,c("testing_labels"))
head(countdf)
GRI(testing_labels,NBPred)
install.packages("qualV")
library(qualV)
GRI(testing_labels,NBPred)
RMSE = RMSE(testing_labels,NBPred,type="dissimilarity")
